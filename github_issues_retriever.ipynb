{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "78c6515b",
   "metadata": {},
   "source": [
    "# GitHub Issues Retriever\n",
    "\n",
    "This notebook demonstrates how to retrieve issues from a specific GitHub repository using the GitHub API. The issues will be filtered with the criteria `is:issue is:closed label:bug linked:pr`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "757bc73e-9884-46b7-8d1a-59b3f7e49ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install langchain\n",
    "!pip install openpyxl\n",
    "!pip install openai\n",
    "!pip install langchain-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ef99479",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import requests\n",
    "import os\n",
    "from typing import Dict, Any, Set, Tuple\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.messages import SystemMessage, HumanMessage\n",
    "from openpyxl import Workbook, load_workbook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deab9156-117d-4fbb-84da-1b520c3c720c",
   "metadata": {},
   "outputs": [],
   "source": [
    "GITHUB_TOKEN = os.getenv('GITHUB_TOKEN')\n",
    "GITHUB_API_URL = os.getenv('GITHUB_API_URL', 'https://api.github.com')\n",
    "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')\n",
    "ANALYZED_ISSUES_FILE = os.getenv('ANALYZED_ISSUES_FILE', 'analyzed_issues.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6499c3d-23ce-408c-9bc0-e555d0310a08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error reading analyzed_issues.xlsx: too many values to unpack (expected 6)\n"
     ]
    }
   ],
   "source": [
    "class AnalyzedIssuesStorage:\n",
    "    def __init__(self, filename=ANALYZED_ISSUES_FILE):\n",
    "        self.filename = filename\n",
    "        self.analyzed_issues = {}\n",
    "        self.visited_pages = {}\n",
    "        self._load()\n",
    "\n",
    "    def _load(self):\n",
    "        if not os.path.exists(self.filename):\n",
    "            workbook = Workbook()\n",
    "            sheet = workbook.active\n",
    "            sheet.title = 'Analyzed Issues'\n",
    "            sheet.append(['issue_id', 'repo_owner', 'repo_name', 'issue_description', 'issue_prompt', \n",
    "                         'issue_url', 'issue_state', 'issue_files', 'issue_pr_url'])\n",
    "            workbook.save(self.filename)\n",
    "            return\n",
    "        \n",
    "        try:\n",
    "            workbook = load_workbook(self.filename)\n",
    "            sheet = workbook.active\n",
    "            \n",
    "            self.analyzed_issues = {}\n",
    "            for row in sheet.iter_rows(min_row=2, values_only=True):\n",
    "                if not row[0]:  \n",
    "                    continue\n",
    "                \n",
    "                issue_id, owner, repo = row[0], row[1], row[2]\n",
    "                if owner not in self.analyzed_issues:\n",
    "                    self.analyzed_issues[owner] = {}\n",
    "                if repo not in self.analyzed_issues[owner]:\n",
    "                    self.analyzed_issues[owner][repo] = []\n",
    "                self.analyzed_issues[owner][repo].append(str(issue_id))\n",
    "            \n",
    "            self.visited_pages = {}\n",
    "            visited_pages_sheet = None\n",
    "            \n",
    "            if 'Visited Pages' in workbook.sheetnames:\n",
    "                visited_pages_sheet = workbook['Visited Pages']\n",
    "            else:\n",
    "                visited_pages_sheet = workbook.create_sheet('Visited Pages')\n",
    "                visited_pages_sheet.append(['repo_owner', 'repo_name', 'page_number'])\n",
    "                workbook.save(self.filename)\n",
    "            \n",
    "            for row in visited_pages_sheet.iter_rows(min_row=2, values_only=True):\n",
    "                if not row[0]:\n",
    "                    continue\n",
    "                \n",
    "                owner, repo, page = row[0], row[1], row[2]\n",
    "                if owner not in self.visited_pages:\n",
    "                    self.visited_pages[owner] = {}\n",
    "                if repo not in self.visited_pages[owner]:\n",
    "                    self.visited_pages[owner][repo] = set()\n",
    "                self.visited_pages[owner][repo].add(int(page))\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error reading {self.filename}: {str(e)}\")\n",
    "            self.analyzed_issues = {}\n",
    "            self.visited_pages = {}\n",
    "    \n",
    "    def save_issue(self, owner: str, repo: str, issue_id: int, description: str, prompt: str, url: str, pr_url: str = \"void\"):\n",
    "        if owner not in self.analyzed_issues:\n",
    "            self.analyzed_issues[owner] = {}\n",
    "        if repo not in self.analyzed_issues[owner]:\n",
    "            self.analyzed_issues[owner][repo] = []\n",
    "        \n",
    "        if str(issue_id) in self.analyzed_issues[owner][repo]:\n",
    "            return False\n",
    "        \n",
    "        self.analyzed_issues[owner][repo].append(str(issue_id))\n",
    "        \n",
    "        try:\n",
    "            workbook = load_workbook(self.filename)\n",
    "            sheet = workbook.active\n",
    "            \n",
    "            sheet.append([\n",
    "                str(issue_id), \n",
    "                owner, \n",
    "                repo, \n",
    "                description, \n",
    "                prompt, \n",
    "                url, \n",
    "                \"REVIEW\",  \n",
    "                \"\",        \n",
    "                pr_url   \n",
    "            ])\n",
    "            \n",
    "            workbook.save(self.filename)\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            print(f\"Error saving to {self.filename}: {str(e)}\")\n",
    "            return False\n",
    "    \n",
    "    def is_analyzed(self, owner: str, repo: str, issue_id: int) -> bool:\n",
    "        return str(issue_id) in self.analyzed_issues.get(owner, {}).get(repo, [])\n",
    "    \n",
    "    def mark_page_as_visited(self, owner: str, repo: str, page: int):\n",
    "        if owner not in self.visited_pages:\n",
    "            self.visited_pages[owner] = {}\n",
    "        if repo not in self.visited_pages[owner]:\n",
    "            self.visited_pages[owner][repo] = set()\n",
    "        \n",
    "        if page in self.visited_pages[owner][repo]:\n",
    "            return\n",
    "        \n",
    "        self.visited_pages[owner][repo].add(page)\n",
    "        \n",
    "        try:\n",
    "            workbook = load_workbook(self.filename)\n",
    "            \n",
    "            if 'Visited Pages' in workbook.sheetnames:\n",
    "                visited_pages_sheet = workbook['Visited Pages']\n",
    "            else:\n",
    "                visited_pages_sheet = workbook.create_sheet('Visited Pages')\n",
    "                visited_pages_sheet.append(['repo_owner', 'repo_name', 'page_number'])\n",
    "            \n",
    "            visited_pages_sheet.append([owner, repo, page])\n",
    "            workbook.save(self.filename)\n",
    "        except Exception as e:\n",
    "            print(f\"Error saving visited page to {self.filename}: {str(e)}\")\n",
    "    \n",
    "    def is_page_visited(self, owner: str, repo: str, page: int) -> bool:\n",
    "        return page in self.visited_pages.get(owner, {}).get(repo, set())\n",
    "    \n",
    "    def get_visited_pages(self, owner: str, repo: str) -> Set[int]:\n",
    "        return self.visited_pages.get(owner, {}).get(repo, set())\n",
    "\n",
    "storage = AnalyzedIssuesStorage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2fcfccc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_github_issues(owner: str, repo: str, page: int = 1, per_page: int = 10):\n",
    "    if not GITHUB_TOKEN:\n",
    "        raise ValueError(\"GITHUB_TOKEN environment variable not set\")\n",
    "        \n",
    "    headers = {\n",
    "        'Authorization': f'token {GITHUB_TOKEN}',\n",
    "        'Accept': 'application/vnd.github.v3+json'\n",
    "    }\n",
    "    params = {\n",
    "        'q': f'repo:{owner}/{repo} is:issue is:closed linked:pr',\n",
    "        'page': page,\n",
    "        'per_page': per_page\n",
    "    }\n",
    "    response = requests.get(f'{GITHUB_API_URL}/search/issues', headers=headers, params=params)\n",
    "    response.raise_for_status()\n",
    "    return response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3284902e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2ae4b59d-71a2-49b7-bbdb-a03934846463",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_issue_description_and_prompt(issue_data: Dict[str, Any]) -> Tuple[str, str]:\n",
    "    llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0, api_key=OPENAI_API_KEY)\n",
    "    \n",
    "    title = issue_data.get('title', '')\n",
    "    body = issue_data.get('body', '') or ''\n",
    "    if len(body) > 1000: \n",
    "        body = body[:1000] + \"...\"\n",
    "    \n",
    "    system_prompt = \"\"\"\n",
    "    You are an expert in analyzing technical issues in code repositories. \n",
    "    Your task is to analyze GitHub issues and provide:\n",
    "\n",
    "    1. A concise description (maximum 5 lines) summarizing the problem stated in the issue.\n",
    "    2. A well-structured prompt (maximum 10 lines) that could be used to request a solution to this issue from a language model. This prompt should request: identification of the files where the problem is located and a concise explanation of the error.\n",
    "        \n",
    "\n",
    "    Respond in JSON format with the keys \"description\" and \"prompt\".\n",
    "    \"\"\"\n",
    "\n",
    "    user_prompt = f\"\"\"\n",
    "    Analyze the following GitHub issue:\n",
    "\n",
    "    Title: {title}\n",
    "\n",
    "    Description:\n",
    "    {body}\n",
    "\n",
    "    Generate:\n",
    "    1. A concise description (maximum 5 lines) summarizing the problem.\n",
    "    2. An optimized prompt (maximum 10 lines) to request a solution for this issue.\n",
    "    \"\"\"\n",
    "    \n",
    "    messages = [\n",
    "        SystemMessage(content=system_prompt),\n",
    "        HumanMessage(content=user_prompt)\n",
    "    ]\n",
    "    \n",
    "    output_parser = JsonOutputParser()\n",
    "    \n",
    "    try:\n",
    "        response = llm.invoke(messages)\n",
    "        parsed_response = output_parser.invoke(response.content)\n",
    "        return parsed_response.get(\"description\", \"\"), parsed_response.get(\"prompt\", \"\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error generating description and prompt: {str(e)}\")\n",
    "        description = f\"Issue related to: {title}\"\n",
    "        prompt = f\"¿How to solve the problem '{title}' in a GitHub repository\"\n",
    "        return description, prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a5f1b4d-f551-4ba8-addb-67bec98362eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def issue_has_linked_pr(issue_data: Dict[str, Any]) -> bool:\n",
    "    \"\"\"\n",
    "    Checks if an issue has a linked pull request.\n",
    "    \n",
    "    Args:\n",
    "        issue_data: The issue data from GitHub API\n",
    "        \n",
    "    Returns:\n",
    "        True if the issue has at least one linked PR, False otherwise\n",
    "    \"\"\"\n",
    "    if \"pull_request\" in issue_data:\n",
    "        return True\n",
    "    \n",
    "    body = issue_data.get('body', '') or ''\n",
    "    \n",
    "    import re\n",
    "    pr_patterns = [\n",
    "        r'(?i)PR\\s+#\\d+',                          # PR #123\n",
    "        r'(?i)pull request\\s+#\\d+',                # pull request #123\n",
    "        r'(?i)linked\\s+to\\s+#\\d+',                 # linked to #123\n",
    "        r'(?i)closes\\s+#\\d+',                      # closes #123\n",
    "        r'(?i)resolves\\s+#\\d+',                    # resolves #123\n",
    "        r'(?i)github\\.com/[^/]+/[^/]+/pull/\\d+',   # Direct PR URL\n",
    "        r'(?i)linked\\s+pull\\s+request'             # mentions of a linked PR\n",
    "    ]\n",
    "    \n",
    "    for pattern in pr_patterns:\n",
    "        if re.search(pattern, body):\n",
    "            return True\n",
    "    \n",
    "    return False\n",
    "\n",
    "def get_linked_pr_url(issue_data: Dict[str, Any], owner: str, repo: str, headers: Dict[str, str]) -> str:\n",
    "    issue_number = issue_data.get('number')\n",
    "    \n",
    "    if \"pull_request\" in issue_data:\n",
    "        return \"void\"\n",
    "    \n",
    "    try:\n",
    "        timeline_url = f'{GITHUB_API_URL}/repos/{owner}/{repo}/issues/{issue_number}/timeline'\n",
    "        headers_with_preview = headers.copy()\n",
    "        headers_with_preview['Accept'] = 'application/vnd.github.mockingbird-preview+json'\n",
    "        \n",
    "        response = requests.get(timeline_url, headers=headers_with_preview)\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            timeline = response.json()\n",
    "            for event in timeline:\n",
    "                if event.get('event') in ['connected', 'cross-referenced'] and 'source' in event:\n",
    "                    source = event.get('source', {})\n",
    "                    if source.get('type') == 'pull_request' and source.get('issue', {}).get('pull_request'):\n",
    "                        return source.get('issue', {}).get('html_url', \"void\")\n",
    "        \n",
    "        search_query = f'repo:{owner}/{repo} is:pr is:merged linked:issue-{issue_number}'\n",
    "        search_url = f'{GITHUB_API_URL}/search/issues'\n",
    "        params = {'q': search_query}\n",
    "        \n",
    "        response = requests.get(search_url, headers=headers, params=params)\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        search_result = response.json()\n",
    "        if search_result.get('total_count', 0) > 0:\n",
    "            return search_result.get('items', [])[0].get('html_url', \"void\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error al obtener PR vinculado para el issue #{issue_number}: {str(e)}\")\n",
    "    \n",
    "    return \"void\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d74d4c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_github_issues(owner: str, repo: str, target_issues: int, per_page: int = 10) -> int:\n",
    "    \"\"\"\n",
    "    Main function to analyze GitHub issues.\n",
    "\n",
    "    Args:\n",
    "        owner: Repository owner\n",
    "        repo: Repository name\n",
    "        target_issues: Target number of issues to analyze\n",
    "        per_page: Number of issues to retrieve per page\n",
    "\n",
    "    Returns:\n",
    "        Number of issues analyzed\n",
    "    \"\"\"\n",
    "    analyzed_count = 0\n",
    "    current_page = 1\n",
    "    visited_pages = storage.get_visited_pages(owner, repo)\n",
    "    \n",
    "    if not GITHUB_TOKEN:\n",
    "        raise ValueError(\"GITHUB_TOKEN environment variable not set\")\n",
    "        \n",
    "    headers = {\n",
    "        'Authorization': f'token {GITHUB_TOKEN}',\n",
    "        'Accept': 'application/vnd.github.v3+json'\n",
    "    }\n",
    "    \n",
    "    if visited_pages:\n",
    "        current_page = max(visited_pages) + 1\n",
    "    \n",
    "    while analyzed_count < target_issues:\n",
    "        if storage.is_page_visited(owner, repo, current_page):\n",
    "            current_page += 1\n",
    "            continue\n",
    "        \n",
    "        try:\n",
    "            print(f\"Fetching page {current_page} for {owner}/{repo}...\")\n",
    "            response_data = fetch_github_issues(owner, repo, current_page, per_page)\n",
    " \n",
    "            storage.mark_page_as_visited(owner, repo, current_page)\n",
    " \n",
    "            issues = response_data.get('items', [])\n",
    "            \n",
    "            if not issues:\n",
    "                print(f\"No more issues found for {owner}/{repo}\")\n",
    "                break\n",
    "            \n",
    "            for issue in issues:\n",
    "                issue_number = issue.get('number')\n",
    "                if not issue_number or storage.is_analyzed(owner, repo, issue_number):\n",
    "                    continue\n",
    "                \n",
    "                has_pr = False\n",
    "                \n",
    "                if issue_has_linked_pr(issue):\n",
    "                    has_pr = True\n",
    "                \n",
    "                if not has_pr:\n",
    "                    print(f\"Skipping issue #{issue_number} - No linked PR found\")\n",
    "                    continue\n",
    "                else:\n",
    "                    print(f\"Issue #{issue_number} has linked PR(s)\")\n",
    "                \n",
    "                description, prompt = generate_issue_description_and_prompt(issue)\n",
    "                \n",
    "                linked_pr_url = get_linked_pr_url(issue, owner, repo, headers)\n",
    "                print(f\"Linked PR URL for issue #{issue_number}: {linked_pr_url}\")\n",
    "                \n",
    "                url = issue.get('html_url', '')\n",
    "                saved = storage.save_issue(owner, repo, issue_number, description, prompt, url, linked_pr_url)\n",
    "                \n",
    "                if saved:\n",
    "                    analyzed_count += 1\n",
    "                    print(f\"Analyzed issue #{issue_number} - Total: {analyzed_count}/{target_issues}\")\n",
    "                \n",
    "                if analyzed_count >= target_issues:\n",
    "                    break\n",
    "            \n",
    "            current_page += 1\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing page {current_page}: {str(e)}\")\n",
    "            current_page += 1\n",
    "            \n",
    "            # If we've had too many errors, better stop\n",
    "            if current_page > 100:  # Arbitrary limit\n",
    "                print(\"Too many errors, stopping\")\n",
    "                break\n",
    "    \n",
    "    return analyzed_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae5f54f4-1573-4077-853e-f10814e21b09",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
