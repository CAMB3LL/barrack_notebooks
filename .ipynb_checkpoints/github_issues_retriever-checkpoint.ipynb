{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "78c6515b",
   "metadata": {},
   "source": [
    "# GitHub Issues Retriever\n",
    "\n",
    "This notebook demonstrates how to retrieve issues from a specific GitHub repository using the GitHub API. The issues will be filtered with the criteria `is:issue is:closed label:bug linked:pr`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "757bc73e-9884-46b7-8d1a-59b3f7e49ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install langchain\n",
    "!pip install openpyxl\n",
    "!pip install openai\n",
    "!pip install langchain-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ef99479",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import requests\n",
    "import os\n",
    "from typing import Dict, Any, Set, Tuple\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.messages import SystemMessage, HumanMessage\n",
    "from openpyxl import Workbook, load_workbook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "deab9156-117d-4fbb-84da-1b520c3c720c",
   "metadata": {},
   "outputs": [],
   "source": [
    "GITHUB_TOKEN = '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'\n",
    "GITHUB_API_URL = 'https://api.github.com'\n",
    "OPENAI_API_KEY = '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'\n",
    "ANALYZED_ISSUES_FILE = 'analyzed_issues.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6499c3d-23ce-408c-9bc0-e555d0310a08",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Set' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mAnalyzedIssuesStorage\u001b[39;00m:\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, filename\u001b[38;5;241m=\u001b[39mANALYZED_ISSUES_FILE):\n\u001b[0;32m      3\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilename \u001b[38;5;241m=\u001b[39m filename\n",
      "Cell \u001b[1;32mIn[2], line 111\u001b[0m, in \u001b[0;36mAnalyzedIssuesStorage\u001b[1;34m()\u001b[0m\n\u001b[0;32m    108\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mis_page_visited\u001b[39m(\u001b[38;5;28mself\u001b[39m, owner: \u001b[38;5;28mstr\u001b[39m, repo: \u001b[38;5;28mstr\u001b[39m, page: \u001b[38;5;28mint\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n\u001b[0;32m    109\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m page \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvisited_pages\u001b[38;5;241m.\u001b[39mget(owner, {})\u001b[38;5;241m.\u001b[39mget(repo, \u001b[38;5;28mset\u001b[39m())\n\u001b[1;32m--> 111\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_visited_pages\u001b[39m(\u001b[38;5;28mself\u001b[39m, owner: \u001b[38;5;28mstr\u001b[39m, repo: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Set[\u001b[38;5;28mint\u001b[39m]:\n\u001b[0;32m    112\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvisited_pages\u001b[38;5;241m.\u001b[39mget(owner, {})\u001b[38;5;241m.\u001b[39mget(repo, \u001b[38;5;28mset\u001b[39m())\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Set' is not defined"
     ]
    }
   ],
   "source": [
    "class AnalyzedIssuesStorage:\n",
    "    def __init__(self, filename=ANALYZED_ISSUES_FILE):\n",
    "        self.filename = filename\n",
    "        self.analyzed_issues = {}\n",
    "        self.visited_pages = {}\n",
    "        self._load()\n",
    "\n",
    "    def _load(self):\n",
    "        if not os.path.exists(self.filename):\n",
    "            workbook = Workbook()\n",
    "            sheet = workbook.active\n",
    "            sheet.title = 'Analyzed Issues'\n",
    "            sheet.append(['issue_id', 'repo_owner', 'repo_name', 'issue_description', 'issue_prompt', 'issue_url'])\n",
    "            workbook.save(self.filename)\n",
    "            return\n",
    "        \n",
    "        try:\n",
    "            workbook = load_workbook(self.filename)\n",
    "            sheet = workbook.active\n",
    "            \n",
    "            self.analyzed_issues = {}\n",
    "            for row in sheet.iter_rows(min_row=2, values_only=True):\n",
    "                if not row[0]:  # Saltarse filas vacÃ­as\n",
    "                    continue\n",
    "                    \n",
    "                issue_id, owner, repo, description, prompt, url = row\n",
    "                if owner not in self.analyzed_issues:\n",
    "                    self.analyzed_issues[owner] = {}\n",
    "                if repo not in self.analyzed_issues[owner]:\n",
    "                    self.analyzed_issues[owner][repo] = []\n",
    "                self.analyzed_issues[owner][repo].append(str(issue_id))\n",
    "            \n",
    "            self.visited_pages = {}\n",
    "            visited_pages_sheet = None\n",
    "            \n",
    "            if 'Visited Pages' in workbook.sheetnames:\n",
    "                visited_pages_sheet = workbook['Visited Pages']\n",
    "            else:\n",
    "                visited_pages_sheet = workbook.create_sheet('Visited Pages')\n",
    "                visited_pages_sheet.append(['repo_owner', 'repo_name', 'page_number'])\n",
    "                workbook.save(self.filename)\n",
    "            \n",
    "            for row in visited_pages_sheet.iter_rows(min_row=2, values_only=True):\n",
    "                if not row[0]:\n",
    "                    continue\n",
    "                \n",
    "                owner, repo, page = row\n",
    "                if owner not in self.visited_pages:\n",
    "                    self.visited_pages[owner] = {}\n",
    "                if repo not in self.visited_pages[owner]:\n",
    "                    self.visited_pages[owner][repo] = set()\n",
    "                self.visited_pages[owner][repo].add(int(page))\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error reading {self.filename}: {str(e)}\")\n",
    "            self.analyzed_issues = {}\n",
    "            self.visited_pages = {}\n",
    "    \n",
    "    def save_issue(self, owner: str, repo: str, issue_id: int, description: str, prompt: str, url: str):\n",
    "        if owner not in self.analyzed_issues:\n",
    "            self.analyzed_issues[owner] = {}\n",
    "        if repo not in self.analyzed_issues[owner]:\n",
    "            self.analyzed_issues[owner][repo] = []\n",
    "        \n",
    "        if str(issue_id) in self.analyzed_issues[owner][repo]:\n",
    "            return False\n",
    "        \n",
    "        self.analyzed_issues[owner][repo].append(str(issue_id))\n",
    "        \n",
    "        try:\n",
    "            workbook = load_workbook(self.filename)\n",
    "            sheet = workbook.active\n",
    "            sheet.append([str(issue_id), owner, repo, description, prompt, url])\n",
    "            workbook.save(self.filename)\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            print(f\"Error saving to {self.filename}: {str(e)}\")\n",
    "            return False\n",
    "    \n",
    "    def is_analyzed(self, owner: str, repo: str, issue_id: int) -> bool:\n",
    "        return str(issue_id) in self.analyzed_issues.get(owner, {}).get(repo, [])\n",
    "    \n",
    "    def mark_page_as_visited(self, owner: str, repo: str, page: int):\n",
    "        if owner not in self.visited_pages:\n",
    "            self.visited_pages[owner] = {}\n",
    "        if repo not in self.visited_pages[owner]:\n",
    "            self.visited_pages[owner][repo] = set()\n",
    "        \n",
    "        if page in self.visited_pages[owner][repo]:\n",
    "            return\n",
    "        \n",
    "        self.visited_pages[owner][repo].add(page)\n",
    "        \n",
    "        try:\n",
    "            workbook = load_workbook(self.filename)\n",
    "            \n",
    "            if 'Visited Pages' in workbook.sheetnames:\n",
    "                visited_pages_sheet = workbook['Visited Pages']\n",
    "            else:\n",
    "                visited_pages_sheet = workbook.create_sheet('Visited Pages')\n",
    "                visited_pages_sheet.append(['repo_owner', 'repo_name', 'page_number'])\n",
    "            \n",
    "            visited_pages_sheet.append([owner, repo, page])\n",
    "            workbook.save(self.filename)\n",
    "        except Exception as e:\n",
    "            print(f\"Error saving visited page to {self.filename}: {str(e)}\")\n",
    "    \n",
    "    def is_page_visited(self, owner: str, repo: str, page: int) -> bool:\n",
    "        return page in self.visited_pages.get(owner, {}).get(repo, set())\n",
    "    \n",
    "    def get_visited_pages(self, owner: str, repo: str) -> Set[int]:\n",
    "        return self.visited_pages.get(owner, {}).get(repo, set())\n",
    "\n",
    "storage = AnalyzedIssuesStorage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fcfccc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_github_issues(owner: str, repo: str, page: int = 1, per_page: int = 10):\n",
    "    if not GITHUB_TOKEN:\n",
    "        raise ValueError(\"GITHUB_TOKEN environment variable not set\")\n",
    "        \n",
    "    headers = {\n",
    "        'Authorization': f'token {GITHUB_TOKEN}',\n",
    "        'Accept': 'application/vnd.github.v3+json'\n",
    "    }\n",
    "    params = {\n",
    "        'q': f'repo:{owner}/{repo} is:issue is:closed linked:pr',\n",
    "        'page': page,\n",
    "        'per_page': per_page\n",
    "    }\n",
    "    response = requests.get(f'{GITHUB_API_URL}/search/issues', headers=headers, params=params)\n",
    "    response.raise_for_status()\n",
    "    return response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ae4b59d-71a2-49b7-bbdb-a03934846463",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_issue_description_and_prompt(issue_data: Dict[str, Any]) -> Tuple[str, str]:\n",
    "    llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0, api_key=OPENAI_API_KEY)\n",
    "    \n",
    "    title = issue_data.get('title', '')\n",
    "    body = issue_data.get('body', '') or ''\n",
    "    if len(body) > 1000: \n",
    "        body = body[:1000] + \"...\"\n",
    "    \n",
    "    system_prompt = \"\"\"\n",
    "    You are an expert in analyzing technical issues in code repositories. \n",
    "    Your task is to analyze GitHub issues and provide:\n",
    "\n",
    "    1. A concise description (maximum 5 lines) summarizing the problem stated in the issue.\n",
    "    2. A well-structured prompt (maximum 10 lines) that could be used to request a solution to this issue from a language model. This prompt should request: identification of the files where the problem is located and a concise explanation of the error.\n",
    "        \n",
    "\n",
    "    Respond in JSON format with the keys \"description\" and \"prompt\".\n",
    "    \"\"\"\n",
    "\n",
    "    user_prompt = f\"\"\"\n",
    "    Analyze the following GitHub issue:\n",
    "\n",
    "    Title: {title}\n",
    "\n",
    "    Description:\n",
    "    {body}\n",
    "\n",
    "    Generate:\n",
    "    1. A concise description (maximum 5 lines) summarizing the problem.\n",
    "    2. An optimized prompt (maximum 10 lines) to request a solution for this issue.\n",
    "    \"\"\"\n",
    "    \n",
    "    messages = [\n",
    "        SystemMessage(content=system_prompt),\n",
    "        HumanMessage(content=user_prompt)\n",
    "    ]\n",
    "    \n",
    "    output_parser = JsonOutputParser()\n",
    "    \n",
    "    try:\n",
    "        response = llm.invoke(messages)\n",
    "        parsed_response = output_parser.invoke(response.content)\n",
    "        return parsed_response.get(\"description\", \"\"), parsed_response.get(\"prompt\", \"\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error generating description and prompt: {str(e)}\")\n",
    "        description = f\"Issue related to: {title}\"\n",
    "        prompt = f\"Â¿How to solve the problem '{title}' in a GitHub repository\"\n",
    "        return description, prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a5f1b4d-f551-4ba8-addb-67bec98362eb",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Dict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21missue_has_linked_pr\u001b[39m(issue_data: Dict[\u001b[38;5;28mstr\u001b[39m, Any]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n\u001b[0;32m      2\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03m    Checks if an issue has a linked pull request.\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;124;03m    \u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;124;03m        True if the issue has at least one linked PR, False otherwise\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpull_request\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m issue_data:\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Dict' is not defined"
     ]
    }
   ],
   "source": [
    "def issue_has_linked_pr(issue_data: Dict[str, Any]) -> bool:\n",
    "    \"\"\"\n",
    "    Checks if an issue has a linked pull request.\n",
    "    \n",
    "    Args:\n",
    "        issue_data: The issue data from GitHub API\n",
    "        \n",
    "    Returns:\n",
    "        True if the issue has at least one linked PR, False otherwise\n",
    "    \"\"\"\n",
    "    if \"pull_request\" in issue_data:\n",
    "        return True\n",
    "    \n",
    "    body = issue_data.get('body', '') or ''\n",
    "    \n",
    "    import re\n",
    "    pr_patterns = [\n",
    "        r'(?i)PR\\s+#\\d+',                          # PR #123\n",
    "        r'(?i)pull request\\s+#\\d+',                # pull request #123\n",
    "        r'(?i)linked\\s+to\\s+#\\d+',                 # linked to #123\n",
    "        r'(?i)closes\\s+#\\d+',                      # closes #123\n",
    "        r'(?i)resolves\\s+#\\d+',                    # resolves #123\n",
    "        r'(?i)github\\.com/[^/]+/[^/]+/pull/\\d+',   # Direct PR URL\n",
    "        r'(?i)linked\\s+pull\\s+request'             # mentions of a linked PR\n",
    "    ]\n",
    "    \n",
    "    for pattern in pr_patterns:\n",
    "        if re.search(pattern, body):\n",
    "            return True\n",
    "    \n",
    "    return False\n",
    "\n",
    "def analyze_github_issues(owner: str, repo: str, target_issues: int, per_page: int = 10) -> int:\n",
    "    \"\"\"\n",
    "    Main function to analyze GitHub issues.\n",
    "\n",
    "    Args:\n",
    "        owner: Repository owner\n",
    "        repo: Repository name\n",
    "        target_issues: Target number of issues to analyze\n",
    "        per_page: Number of issues to retrieve per page\n",
    "\n",
    "    Returns:\n",
    "        Number of issues analyzed\n",
    "    \"\"\"\n",
    "    analyzed_count = 0\n",
    "    current_page = 1\n",
    "    visited_pages = storage.get_visited_pages(owner, repo)\n",
    "    \n",
    "    if visited_pages:\n",
    "        current_page = max(visited_pages) + 1\n",
    "    \n",
    "    while analyzed_count < target_issues:\n",
    "        if storage.is_page_visited(owner, repo, current_page):\n",
    "            current_page += 1\n",
    "            continue\n",
    "        \n",
    "        try:\n",
    "            print(f\"Fetching page {current_page} for {owner}/{repo}...\")\n",
    "            response_data = fetch_github_issues(owner, repo, current_page, per_page)\n",
    " \n",
    "            storage.mark_page_as_visited(owner, repo, current_page)\n",
    " \n",
    "            issues = response_data.get('items', [])\n",
    "            \n",
    "            if not issues:\n",
    "                print(f\"No more issues found for {owner}/{repo}\")\n",
    "                break\n",
    "            \n",
    "            for issue in issues:\n",
    "                issue_number = issue.get('number')\n",
    "                if not issue_number or storage.is_analyzed(owner, repo, issue_number):\n",
    "                    continue\n",
    "                \n",
    "                # VALIDATION: Check if the issue has a linked PR (mandatory)\n",
    "                has_pr = False\n",
    "                \n",
    "                if issue_has_linked_pr(issue):\n",
    "                    has_pr = True\n",
    "                \n",
    "                if not has_pr:\n",
    "                    print(f\"Skipping issue #{issue_number} - No linked PR found\")\n",
    "                    continue\n",
    "                else:\n",
    "                    print(f\"Issue #{issue_number} has linked PR(s)\")\n",
    "                \n",
    "                description, prompt = generate_issue_description_and_prompt(issue)\n",
    "                \n",
    "                url = issue.get('html_url', '')\n",
    "                saved = storage.save_issue(owner, repo, issue_number, description, prompt, url)\n",
    "                \n",
    "                if saved:\n",
    "                    analyzed_count += 1\n",
    "                    print(f\"Analyzed issue #{issue_number} - Total: {analyzed_count}/{target_issues}\")\n",
    "                \n",
    "                if analyzed_count >= target_issues:\n",
    "                    break\n",
    "            \n",
    "            current_page += 1\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing page {current_page}: {str(e)}\")\n",
    "            current_page += 1\n",
    "            \n",
    "            # If we've had too many errors, better stop\n",
    "            if current_page > 100:  # Arbitrary limit\n",
    "                print(\"Too many errors, stopping\")\n",
    "                break\n",
    "    \n",
    "    return analyzed_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e99b876f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching page 1 for jquense/react-big-calendar...\n",
      "Skipping issue #2701 - No linked PR found\n",
      "Skipping issue #2680 - No linked PR found\n",
      "Skipping issue #2676 - No linked PR found\n",
      "Skipping issue #2634 - No linked PR found\n",
      "Skipping issue #2618 - No linked PR found\n",
      "Fetching page 2 for jquense/react-big-calendar...\n",
      "Skipping issue #2607 - No linked PR found\n",
      "Skipping issue #2601 - No linked PR found\n",
      "Skipping issue #2595 - No linked PR found\n",
      "Skipping issue #2584 - No linked PR found\n",
      "Skipping issue #2565 - No linked PR found\n",
      "Fetching page 3 for jquense/react-big-calendar...\n",
      "Skipping issue #2563 - No linked PR found\n",
      "Skipping issue #2556 - No linked PR found\n",
      "Skipping issue #2529 - No linked PR found\n",
      "Skipping issue #2391 - No linked PR found\n",
      "Skipping issue #2386 - No linked PR found\n",
      "Fetching page 4 for jquense/react-big-calendar...\n",
      "Skipping issue #2383 - No linked PR found\n",
      "Skipping issue #2361 - No linked PR found\n",
      "Skipping issue #2330 - No linked PR found\n",
      "Skipping issue #2296 - No linked PR found\n",
      "Skipping issue #2240 - No linked PR found\n",
      "Fetching page 5 for jquense/react-big-calendar...\n",
      "Skipping issue #2233 - No linked PR found\n",
      "Skipping issue #2231 - No linked PR found\n",
      "Skipping issue #2222 - No linked PR found\n",
      "Skipping issue #2207 - No linked PR found\n",
      "Skipping issue #2201 - No linked PR found\n",
      "Fetching page 6 for jquense/react-big-calendar...\n",
      "Skipping issue #2200 - No linked PR found\n",
      "Skipping issue #2198 - No linked PR found\n",
      "Skipping issue #2193 - No linked PR found\n",
      "Skipping issue #2156 - No linked PR found\n",
      "Skipping issue #2153 - No linked PR found\n",
      "Fetching page 7 for jquense/react-big-calendar...\n",
      "Skipping issue #2147 - No linked PR found\n",
      "Issue #2115 has linked PR(s)\n",
      "Analyzed issue #2115 - Total: 1/20\n",
      "Skipping issue #2110 - No linked PR found\n",
      "Skipping issue #2037 - No linked PR found\n",
      "Skipping issue #2028 - No linked PR found\n",
      "Fetching page 8 for jquense/react-big-calendar...\n",
      "Skipping issue #1953 - No linked PR found\n",
      "Skipping issue #1924 - No linked PR found\n",
      "Skipping issue #1909 - No linked PR found\n",
      "Issue #1898 has linked PR(s)\n",
      "Analyzed issue #1898 - Total: 2/20\n",
      "Skipping issue #1878 - No linked PR found\n",
      "Fetching page 9 for jquense/react-big-calendar...\n",
      "Skipping issue #1864 - No linked PR found\n",
      "Skipping issue #1813 - No linked PR found\n",
      "Skipping issue #1708 - No linked PR found\n",
      "Skipping issue #1649 - No linked PR found\n",
      "Skipping issue #1567 - No linked PR found\n",
      "Fetching page 10 for jquense/react-big-calendar...\n",
      "Skipping issue #1527 - No linked PR found\n",
      "Skipping issue #1481 - No linked PR found\n",
      "Skipping issue #1474 - No linked PR found\n",
      "Skipping issue #1397 - No linked PR found\n",
      "Skipping issue #1259 - No linked PR found\n",
      "Fetching page 11 for jquense/react-big-calendar...\n",
      "Skipping issue #1203 - No linked PR found\n",
      "Skipping issue #1147 - No linked PR found\n",
      "Skipping issue #1098 - No linked PR found\n",
      "Skipping issue #1081 - No linked PR found\n",
      "Skipping issue #1060 - No linked PR found\n",
      "Fetching page 12 for jquense/react-big-calendar...\n",
      "Skipping issue #1044 - No linked PR found\n",
      "Skipping issue #1040 - No linked PR found\n",
      "Skipping issue #1017 - No linked PR found\n",
      "Skipping issue #1006 - No linked PR found\n",
      "Skipping issue #968 - No linked PR found\n",
      "Fetching page 13 for jquense/react-big-calendar...\n",
      "Skipping issue #939 - No linked PR found\n",
      "Skipping issue #828 - No linked PR found\n",
      "Skipping issue #816 - No linked PR found\n",
      "Skipping issue #807 - No linked PR found\n",
      "Skipping issue #636 - No linked PR found\n",
      "Fetching page 14 for jquense/react-big-calendar...\n",
      "Skipping issue #630 - No linked PR found\n",
      "Skipping issue #512 - No linked PR found\n",
      "Skipping issue #385 - No linked PR found\n",
      "Skipping issue #360 - No linked PR found\n",
      "Skipping issue #357 - No linked PR found\n",
      "Fetching page 15 for jquense/react-big-calendar...\n",
      "Skipping issue #356 - No linked PR found\n",
      "Skipping issue #333 - No linked PR found\n",
      "Skipping issue #261 - No linked PR found\n",
      "Skipping issue #113 - No linked PR found\n",
      "Skipping issue #71 - No linked PR found\n",
      "Fetching page 16 for jquense/react-big-calendar...\n",
      "Skipping issue #69 - No linked PR found\n",
      "Skipping issue #36 - No linked PR found\n",
      "Fetching page 17 for jquense/react-big-calendar...\n",
      "No more issues found for jquense/react-big-calendar\n",
      "Successfully analyzed 2 issues from jquense/react-big-calendar\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    owner = 'brianc' \n",
    "    repo = 'node-postgres' \n",
    "    target_issues = 20\n",
    "    per_page = 5\n",
    "\n",
    "    try:\n",
    "        if not GITHUB_TOKEN:\n",
    "            print(\"ERROR: GITHUB_TOKEN environment variable not set\")\n",
    "            print(\"Please set it with: export GITHUB_TOKEN=your_token_here\")\n",
    "            return\n",
    "\n",
    "        # Run the analysis\n",
    "        analyzed_count = analyze_github_issues(owner, repo, target_issues, per_page)\n",
    "        print(f\"Successfully analyzed {analyzed_count} issues from {owner}/{repo}\")\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f'Error: {str(e)}')\n",
    "\n",
    "# Run the main function\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae5f54f4-1573-4077-853e-f10814e21b09",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
