{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "78c6515b",
   "metadata": {},
   "source": [
    "# GitHub Issues Retriever\n",
    "\n",
    "This notebook demonstrates how to retrieve issues from a specific GitHub repository using the GitHub API. The issues will be filtered with the criteria `is:issue is:closed label:bug linked:pr`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "757bc73e-9884-46b7-8d1a-59b3f7e49ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install langchain\n",
    "!pip install openpyxl\n",
    "!pip install openai\n",
    "!pip install langchain-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2ef99479",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import requests\n",
    "import os\n",
    "from typing import Dict, Any, Set, Tuple\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.messages import SystemMessage, HumanMessage\n",
    "from openpyxl import Workbook, load_workbook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deab9156-117d-4fbb-84da-1b520c3c720c",
   "metadata": {},
   "outputs": [],
   "source": [
    "GITHUB_TOKEN = env.get('GITHUB_TOKEN')\n",
    "GITHUB_API_URL = 'https://api.github.com'\n",
    "OPENAI_API_KEY = env.get('OPENAI_API_KEY')\n",
    "ANALYZED_ISSUES_FILE ='analyzed_issues.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e6499c3d-23ce-408c-9bc0-e555d0310a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AnalyzedIssuesStorage:\n",
    "    def __init__(self, filename=ANALYZED_ISSUES_FILE):\n",
    "        self.filename = filename\n",
    "        self.analyzed_issues = {}\n",
    "        self.visited_pages = {}\n",
    "        self._load()\n",
    "\n",
    "    def _load(self):\n",
    "        if not os.path.exists(self.filename):\n",
    "            workbook = Workbook()\n",
    "            sheet = workbook.active\n",
    "            sheet.title = 'Analyzed Issues'\n",
    "            sheet.append(['issue_id', 'repo_owner', 'repo_name', 'issue_description', 'issue_prompt', \n",
    "                         'issue_url', 'issue_state', 'issue_files', 'issue_pr_url'])\n",
    "            workbook.save(self.filename)\n",
    "            return\n",
    "        \n",
    "        try:\n",
    "            workbook = load_workbook(self.filename)\n",
    "            sheet = workbook.active\n",
    "            \n",
    "            self.analyzed_issues = {}\n",
    "            for row in sheet.iter_rows(min_row=2, values_only=True):\n",
    "                if not row[0]:  \n",
    "                    continue\n",
    "                \n",
    "                issue_id, owner, repo = row[0], row[1], row[2]\n",
    "                if owner not in self.analyzed_issues:\n",
    "                    self.analyzed_issues[owner] = {}\n",
    "                if repo not in self.analyzed_issues[owner]:\n",
    "                    self.analyzed_issues[owner][repo] = []\n",
    "                self.analyzed_issues[owner][repo].append(str(issue_id))\n",
    "            \n",
    "            self.visited_pages = {}\n",
    "            visited_pages_sheet = None\n",
    "            \n",
    "            if 'Visited Pages' in workbook.sheetnames:\n",
    "                visited_pages_sheet = workbook['Visited Pages']\n",
    "            else:\n",
    "                visited_pages_sheet = workbook.create_sheet('Visited Pages')\n",
    "                visited_pages_sheet.append(['repo_owner', 'repo_name', 'page_number'])\n",
    "                workbook.save(self.filename)\n",
    "            \n",
    "            for row in visited_pages_sheet.iter_rows(min_row=2, values_only=True):\n",
    "                if not row[0]:\n",
    "                    continue\n",
    "                \n",
    "                owner, repo, page = row[0], row[1], row[2]\n",
    "                if owner not in self.visited_pages:\n",
    "                    self.visited_pages[owner] = {}\n",
    "                if repo not in self.visited_pages[owner]:\n",
    "                    self.visited_pages[owner][repo] = set()\n",
    "                self.visited_pages[owner][repo].add(int(page))\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error reading {self.filename}: {str(e)}\")\n",
    "            self.analyzed_issues = {}\n",
    "            self.visited_pages = {}\n",
    "    \n",
    "    def save_issue(self, owner: str, repo: str, issue_id: int, description: str, prompt: str, url: str, pr_url: str = \"void\"):\n",
    "        if owner not in self.analyzed_issues:\n",
    "            self.analyzed_issues[owner] = {}\n",
    "        if repo not in self.analyzed_issues[owner]:\n",
    "            self.analyzed_issues[owner][repo] = []\n",
    "        \n",
    "        if str(issue_id) in self.analyzed_issues[owner][repo]:\n",
    "            return False\n",
    "        \n",
    "        self.analyzed_issues[owner][repo].append(str(issue_id))\n",
    "        \n",
    "        try:\n",
    "            workbook = load_workbook(self.filename)\n",
    "            sheet = workbook.active\n",
    "            \n",
    "            sheet.append([\n",
    "                str(issue_id), \n",
    "                owner, \n",
    "                repo, \n",
    "                description, \n",
    "                prompt, \n",
    "                url, \n",
    "                \"REVIEW\",  \n",
    "                \"\",        \n",
    "                pr_url   \n",
    "            ])\n",
    "            \n",
    "            workbook.save(self.filename)\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            print(f\"Error saving to {self.filename}: {str(e)}\")\n",
    "            return False\n",
    "    \n",
    "    def is_analyzed(self, owner: str, repo: str, issue_id: int) -> bool:\n",
    "        return str(issue_id) in self.analyzed_issues.get(owner, {}).get(repo, [])\n",
    "    \n",
    "    def mark_page_as_visited(self, owner: str, repo: str, page: int):\n",
    "        if owner not in self.visited_pages:\n",
    "            self.visited_pages[owner] = {}\n",
    "        if repo not in self.visited_pages[owner]:\n",
    "            self.visited_pages[owner][repo] = set()\n",
    "        \n",
    "        if page in self.visited_pages[owner][repo]:\n",
    "            return\n",
    "        \n",
    "        self.visited_pages[owner][repo].add(page)\n",
    "        \n",
    "        try:\n",
    "            workbook = load_workbook(self.filename)\n",
    "            \n",
    "            if 'Visited Pages' in workbook.sheetnames:\n",
    "                visited_pages_sheet = workbook['Visited Pages']\n",
    "            else:\n",
    "                visited_pages_sheet = workbook.create_sheet('Visited Pages')\n",
    "                visited_pages_sheet.append(['repo_owner', 'repo_name', 'page_number'])\n",
    "            \n",
    "            visited_pages_sheet.append([owner, repo, page])\n",
    "            workbook.save(self.filename)\n",
    "        except Exception as e:\n",
    "            print(f\"Error saving visited page to {self.filename}: {str(e)}\")\n",
    "    \n",
    "    def is_page_visited(self, owner: str, repo: str, page: int) -> bool:\n",
    "        return page in self.visited_pages.get(owner, {}).get(repo, set())\n",
    "    \n",
    "    def get_visited_pages(self, owner: str, repo: str) -> Set[int]:\n",
    "        return self.visited_pages.get(owner, {}).get(repo, set())\n",
    "\n",
    "storage = AnalyzedIssuesStorage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2fcfccc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_github_issues(owner: str, repo: str, page: int = 1, per_page: int = 10):\n",
    "    if not GITHUB_TOKEN:\n",
    "        raise ValueError(\"GITHUB_TOKEN environment variable not set\")\n",
    "        \n",
    "    headers = {\n",
    "        'Authorization': f'token {GITHUB_TOKEN}',\n",
    "        'Accept': 'application/vnd.github.v3+json'\n",
    "    }\n",
    "    params = {\n",
    "        'q': f'repo:{owner}/{repo} is:issue is:closed linked:pr',\n",
    "        'page': page,\n",
    "        'per_page': per_page\n",
    "    }\n",
    "    response = requests.get(f'{GITHUB_API_URL}/search/issues', headers=headers, params=params)\n",
    "    response.raise_for_status()\n",
    "    return response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2ae4b59d-71a2-49b7-bbdb-a03934846463",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_issue_description_and_prompt(issue_data: Dict[str, Any]) -> Tuple[str, str]:\n",
    "    llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0, api_key=OPENAI_API_KEY)\n",
    "    \n",
    "    title = issue_data.get('title', '')\n",
    "    body = issue_data.get('body', '') or ''\n",
    "    if len(body) > 1000: \n",
    "        body = body[:1000] + \"...\"\n",
    "    \n",
    "    system_prompt = \"\"\"\n",
    "    You are an expert in analyzing technical issues in code repositories. \n",
    "    Your task is to analyze GitHub issues and provide:\n",
    "\n",
    "    1. A concise description (maximum 5 lines) summarizing the problem stated in the issue.\n",
    "    2. A well-structured prompt (maximum 10 lines) that could be used to request a solution to this issue from a language model. This prompt should request: identification of the files where the problem is located and a concise explanation of the error.\n",
    "        \n",
    "\n",
    "    Respond in JSON format with the keys \"description\" and \"prompt\".\n",
    "    \"\"\"\n",
    "\n",
    "    user_prompt = f\"\"\"\n",
    "    Analyze the following GitHub issue:\n",
    "\n",
    "    Title: {title}\n",
    "\n",
    "    Description:\n",
    "    {body}\n",
    "\n",
    "    Generate:\n",
    "    1. A concise description (maximum 5 lines) summarizing the problem.\n",
    "    2. An optimized prompt (maximum 10 lines) to request a solution for this issue.\n",
    "    \"\"\"\n",
    "    \n",
    "    messages = [\n",
    "        SystemMessage(content=system_prompt),\n",
    "        HumanMessage(content=user_prompt)\n",
    "    ]\n",
    "    \n",
    "    output_parser = JsonOutputParser()\n",
    "    \n",
    "    try:\n",
    "        response = llm.invoke(messages)\n",
    "        parsed_response = output_parser.invoke(response.content)\n",
    "        return parsed_response.get(\"description\", \"\"), parsed_response.get(\"prompt\", \"\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error generating description and prompt: {str(e)}\")\n",
    "        description = f\"Issue related to: {title}\"\n",
    "        prompt = f\"¿How to solve the problem '{title}' in a GitHub repository\"\n",
    "        return description, prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7a5f1b4d-f551-4ba8-addb-67bec98362eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_linked_pr_url(issue_data: Dict[str, Any], owner: str, repo: str, headers: Dict[str, str]) -> str:\n",
    "    \"\"\"\n",
    "    Gets the URL of the first pull request directly linked to an issue.\n",
    "    Only retrieves PRs that are formally linked to the issue.\n",
    "    \n",
    "    Args:\n",
    "        issue_data: Issue data obtained from the GitHub API\n",
    "        owner: Repository owner\n",
    "        repo: Repository name\n",
    "        headers: Headers for GitHub API requests\n",
    "        \n",
    "    Returns:\n",
    "        URL of the first linked PR or \"void\" if none exists\n",
    "    \"\"\"\n",
    "    issue_number = issue_data.get('number')\n",
    "    \n",
    "    if \"pull_request\" in issue_data:\n",
    "        return \"void\"\n",
    "    \n",
    "    try:\n",
    "        # The most reliable way to find directly linked PRs is through the timeline API\n",
    "        timeline_url = f'{GITHUB_API_URL}/repos/{owner}/{repo}/issues/{issue_number}/timeline'\n",
    "        headers_with_preview = headers.copy()\n",
    "        headers_with_preview['Accept'] = 'application/vnd.github.mockingbird-preview+json'\n",
    "        \n",
    "        response = requests.get(timeline_url, headers=headers_with_preview)\n",
    "        if response.status_code == 200:\n",
    "            timeline = response.json()\n",
    "            \n",
    "            for event in timeline:\n",
    "                if event.get('event') == 'connected':\n",
    "                    source = event.get('source', {})\n",
    "                    if source.get('type') == 'pull_request' and source.get('issue', {}).get('pull_request'):\n",
    "                        return source.get('issue', {}).get('html_url', \"void\")\n",
    "                \n",
    "                if event.get('event') == 'cross-referenced':\n",
    "                    source = event.get('source', {})\n",
    "                    if source.get('type') == 'pull_request' and source.get('issue', {}).get('pull_request'):\n",
    "                        # Check if this PR has a closing reference to our issue\n",
    "                        pr_number = source.get('issue', {}).get('number')\n",
    "                        pr_url = f'{GITHUB_API_URL}/repos/{owner}/{repo}/pulls/{pr_number}'\n",
    "                        \n",
    "                        pr_response = requests.get(pr_url, headers=headers)\n",
    "                        if pr_response.status_code == 200:\n",
    "                            pr_data = pr_response.json()\n",
    "                            body = pr_data.get('body', '') or ''\n",
    "                            \n",
    "                            # Check if this PR explicitly closes the \n",
    "                            closes_patterns = [\n",
    "                                f\"closes #{issue_number}\",\n",
    "                                f\"fixes #{issue_number}\",\n",
    "                                f\"resolves #{issue_number}\"\n",
    "                            ]\n",
    "                            \n",
    "                            for pattern in closes_patterns:\n",
    "                                if pattern.lower() in body.lower():\n",
    "                                    return source.get('issue', {}).get('html_url', \"void\")\n",
    "            \n",
    "            for event in timeline:\n",
    "                if event.get('event') == 'closed' and event.get('commit_id'):\n",
    "                    commit_sha = event.get('commit_id')\n",
    "                    commit_url = f'{GITHUB_API_URL}/repos/{owner}/{repo}/commits/{commit_sha}'\n",
    "                    \n",
    "                    commit_response = requests.get(commit_url, headers=headers)\n",
    "                    if commit_response.status_code == 200:\n",
    "                        commit_data = commit_response.json()\n",
    "                        commit_message = commit_data.get('commit', {}).get('message', '')\n",
    "                        \n",
    "                        if f\"#{issue_number}\" in commit_message:\n",
    "                            pr_search_url = f'{GITHUB_API_URL}/search/issues'\n",
    "                            pr_params = {\n",
    "                                'q': f'repo:{owner}/{repo} is:pr {commit_sha}'\n",
    "                            }\n",
    "                            \n",
    "                            pr_response = requests.get(pr_search_url, headers=headers, params=pr_params)\n",
    "                            if pr_response.status_code == 200:\n",
    "                                pr_data = pr_response.json()\n",
    "                                if pr_data.get('total_count', 0) > 0:\n",
    "                                    return pr_data.get('items', [])[0].get('html_url', \"void\")\n",
    "        \n",
    "        search_url = f'{GITHUB_API_URL}/search/issues'\n",
    "        search_query = f'repo:{owner}/{repo} is:pr \"Closes #{issue_number}\"'\n",
    "        params = {'q': search_query}\n",
    "        \n",
    "        search_response = requests.get(search_url, headers=headers, params=params)\n",
    "        if search_response.status_code == 200:\n",
    "            search_result = search_response.json()\n",
    "            if search_result.get('total_count', 0) > 0:\n",
    "                return search_result.get('items', [])[0].get('html_url', \"void\")\n",
    "        \n",
    "        for keyword in [\"Fixes\", \"Resolves\"]:\n",
    "            search_query = f'repo:{owner}/{repo} is:pr \"{keyword} #{issue_number}\"'\n",
    "            params = {'q': search_query}\n",
    "            \n",
    "            search_response = requests.get(search_url, headers=headers, params=params)\n",
    "            if search_response.status_code == 200:\n",
    "                search_result = search_response.json()\n",
    "                if search_result.get('total_count', 0) > 0:\n",
    "                    return search_result.get('items', [])[0].get('html_url', \"void\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error getting linked PR for issue #{issue_number}: {str(e)}\")\n",
    "    \n",
    "    return \"void\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d74d4c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_github_issues(owner: str, repo: str, target_issues: int, per_page: int = 10) -> int:\n",
    "    \"\"\"\n",
    "    Main function to analyze GitHub issues.\n",
    "\n",
    "    Args:\n",
    "        owner: Repository owner\n",
    "        repo: Repository name\n",
    "        target_issues: Target number of issues to analyze\n",
    "        per_page: Number of issues to retrieve per page\n",
    "\n",
    "    Returns:\n",
    "        Number of issues analyzed\n",
    "    \"\"\"\n",
    "    analyzed_count = 0\n",
    "    current_page = 1\n",
    "    visited_pages = storage.get_visited_pages(owner, repo)\n",
    "    \n",
    "    if not GITHUB_TOKEN:\n",
    "        raise ValueError(\"GITHUB_TOKEN environment variable not set\")\n",
    "        \n",
    "    headers = {\n",
    "        'Authorization': f'token {GITHUB_TOKEN}',\n",
    "        'Accept': 'application/vnd.github.v3+json'\n",
    "    }\n",
    "    \n",
    "    if visited_pages:\n",
    "        current_page = max(visited_pages) + 1\n",
    "    \n",
    "    while analyzed_count < target_issues:\n",
    "        if storage.is_page_visited(owner, repo, current_page):\n",
    "            current_page += 1\n",
    "            continue\n",
    "        \n",
    "        try:\n",
    "            print(f\"Fetching page {current_page} for {owner}/{repo}...\")\n",
    "            response_data = fetch_github_issues(owner, repo, current_page, per_page)\n",
    " \n",
    "            storage.mark_page_as_visited(owner, repo, current_page)\n",
    " \n",
    "            issues = response_data.get('items', [])\n",
    "            \n",
    "            if not issues:\n",
    "                print(f\"No more issues found for {owner}/{repo}\")\n",
    "                break\n",
    "            \n",
    "            for issue in issues:\n",
    "                issue_number = issue.get('number')\n",
    "                if not issue_number or storage.is_analyzed(owner, repo, issue_number):\n",
    "                    continue\n",
    "                           \n",
    "                # description, prompt = generate_issue_description_and_prompt(issue)\n",
    "                \n",
    "                linked_pr_url = get_linked_pr_url(issue, owner, repo, headers)\n",
    "                \n",
    "                if linked_pr_url == \"void\":\n",
    "                    print(f\"Skipping issue #{issue_number} - No linked PR found\")\n",
    "                    continue\n",
    "                else:\n",
    "                    print(f\"Linked PR URL for issue #{issue_number}: {linked_pr_url}\")\n",
    "                \n",
    "                url = issue.get('html_url', '')\n",
    "                saved = storage.save_issue(owner, repo, issue_number, description, prompt, url, linked_pr_url)\n",
    "                \n",
    "                if saved:\n",
    "                    analyzed_count += 1\n",
    "                    print(f\"Analyzed issue #{issue_number} - Total: {analyzed_count}/{target_issues}\")\n",
    "                \n",
    "                if analyzed_count >= target_issues:\n",
    "                    break\n",
    "            \n",
    "            current_page += 1\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing page {current_page}: {str(e)}\")\n",
    "            current_page += 1\n",
    "            \n",
    "            # If we've had too many errors, better stop\n",
    "            if current_page > 100:  # Arbitrary limit\n",
    "                print(\"Too many errors, stopping\")\n",
    "                break\n",
    "    \n",
    "    return analyzed_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ae5f54f4-1573-4077-853e-f10814e21b09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching page 1 for reactjs/react-rails...\n",
      "Linked PR URL for issue #1311: https://github.com/reactjs/react-rails/pull/1312\n",
      "Analyzed issue #1311 - Total: 1/10\n",
      "Linked PR URL for issue #1276: https://github.com/reactjs/react-rails/pull/1278\n",
      "Analyzed issue #1276 - Total: 2/10\n",
      "Fetching page 2 for reactjs/react-rails...\n",
      "Linked PR URL for issue #1258: https://github.com/reactjs/react-rails/pull/1269\n",
      "Analyzed issue #1258 - Total: 3/10\n",
      "Linked PR URL for issue #1249: https://github.com/reactjs/react-rails/pull/1268\n",
      "Analyzed issue #1249 - Total: 4/10\n",
      "Fetching page 3 for reactjs/react-rails...\n",
      "Linked PR URL for issue #1211: https://github.com/reactjs/react-rails/pull/1214\n",
      "Analyzed issue #1211 - Total: 5/10\n",
      "Linked PR URL for issue #1195: https://github.com/reactjs/react-rails/pull/1218\n",
      "Analyzed issue #1195 - Total: 6/10\n",
      "Fetching page 4 for reactjs/react-rails...\n",
      "Linked PR URL for issue #1193: https://github.com/reactjs/react-rails/pull/1198\n",
      "Analyzed issue #1193 - Total: 7/10\n",
      "Linked PR URL for issue #1171: https://github.com/reactjs/react-rails/pull/1173\n",
      "Analyzed issue #1171 - Total: 8/10\n",
      "Fetching page 5 for reactjs/react-rails...\n",
      "Linked PR URL for issue #1095: https://github.com/reactjs/react-rails/pull/1314\n",
      "Analyzed issue #1095 - Total: 9/10\n",
      "Linked PR URL for issue #1067: https://github.com/reactjs/react-rails/pull/1271\n",
      "Analyzed issue #1067 - Total: 10/10\n",
      "Successfully analyzed 10 issues from reactjs/react-rails\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    owner = 'reactjs' \n",
    "    repo = 'react-rails' \n",
    "    target_issues = 10\n",
    "    per_page = 2\n",
    "\n",
    "    try:\n",
    "        if not GITHUB_TOKEN:\n",
    "            print(\"ERROR: GITHUB_TOKEN environment variable not set\")\n",
    "            print(\"Please set it with: export GITHUB_TOKEN=your_token_here\")\n",
    "            return\n",
    "\n",
    "        # Run the analysis\n",
    "        analyzed_count = analyze_github_issues(owner, repo, target_issues, per_page)\n",
    "        print(f\"Successfully analyzed {analyzed_count} issues from {owner}/{repo}\")\n",
    "        \n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f'Error: {str(e)}')\n",
    "\n",
    "# Run the main function\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76287785-355e-4bee-bbda-3d7a36a4ff30",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
